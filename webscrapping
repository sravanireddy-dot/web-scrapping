#project 2:web scrapping
import requests
from bs4 import BeautifulSoup
import pandas
import argparse
import connect

parser = argparse.ArgumentParser()
parse.add_argument("--page_num_max", help="Enter the number of pages to parse", type=int)
parser.add_argument("--dbname:, help="Enter the number of pages to parse", type=int)
args = parser.parse_args()

oyo_url = "https://www.oyorooms.com/hotels-in-bangalore/?page="
page_num_MAX = 3
scrapped_info_list = []
connect.connect(args.dbname)

for page_num in range(1,page_num_MAX):
    url = oyo_url + str(page_num)
    print("GET Request for:"+)
    req = requests.get(oyo_url + str(page_num))
    content = req.content
    
    soup = BeautifulSoup(content, "html.parser")
    
    all_hotels = soup.find_all("div", {"class": "hotelCardListing"})
    scraped_info_list = []
    
    for hotel in all hotels:
        hotel_dict = {}
        hotel_dict["name"] = hotel.find("h3", {"class": "ListingHOtelDescription_hotelName"}).text
        hotel_dict["address"] = hotel.find("span", {"itemprop": "streetaddress"}).text
        hotel_dict["price"] = hotel.find("span", {"class": "ListingPrice_finalPrice"}).text
        #try .... except
        try:
